services:
  postgres:
    image: postgres:18.2-trixie
    restart: unless-stopped
    environment:
      POSTGRES_DB: labeling
      POSTGRES_USER: labeling
      POSTGRES_PASSWORD: labeling_e2e
    volumes:
      - e2e_postgres_data:/var/lib/postgresql
      - ../saegim-backend/migrations/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    ports:
      - "25432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U labeling -d labeling"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - saegim-e2e-net

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    ports:
      - "26379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - saegim-e2e-net
    profiles:
      - gpu

  backend:
    build:
      context: ../saegim-backend
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://labeling:labeling_e2e@postgres:5432/labeling
      API_HOST: "0.0.0.0"
      API_PORT: "5000"
      STORAGE_PATH: /workspace/storage
      CORS_ORIGINS: '["http://localhost:23000"]'
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/1
      LOG_LEVEL: INFO
    volumes:
      - e2e_storage:/workspace/storage
    ports:
      - "25000:5000"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5000/api/v1/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - saegim-e2e-net

  celery-worker:
    build:
      context: ../saegim-backend
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://labeling:labeling_e2e@postgres:5432/labeling
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/1
      STORAGE_PATH: /workspace/storage
      LOG_LEVEL: INFO
    volumes:
      - e2e_storage:/workspace/storage
    command: >
      celery -A saegim.tasks.celery_app worker
      --loglevel=info
      --concurrency=1
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - saegim-e2e-net
    profiles:
      - gpu

  vllm:
    image: vllm/vllm-openai:v0.15.0
    runtime: nvidia
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      HF_HOME: /root/.cache/huggingface
    volumes:
      - ${HF_CACHE_DIR:-~/.cache/huggingface}:/root/.cache/huggingface
    ports:
      - "28000:8000"
    ipc: host
    command: >
      --model datalab-to/chandra
      --gpu-memory-utilization 0.9
      --max-model-len 8192
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/v1/models || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 20
      start_period: 120s
    networks:
      - saegim-e2e-net
    profiles:
      - gpu

  frontend:
    build:
      context: ../saegim-frontend
      args:
        VITE_API_URL: http://localhost:25000
    restart: unless-stopped
    ports:
      - "23000:80"
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - saegim-e2e-net

volumes:
  e2e_postgres_data:
  e2e_storage:

networks:
  saegim-e2e-net:
    driver: bridge
